#!/usr/bin/env python3
"""
Vision â†’ Character â†’ Director ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³çµ±åˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
è¦³å…‰åœ°ã®ç”»åƒãƒ»å‹•ç”»ã«å¯¾ã—ã¦ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ»è§£èª¬ã‚’ç”Ÿæˆã—ã€å“è³ªåˆ¤å®šã™ã‚‹ã€‚
"""

import sys
import json
from pathlib import Path
from typing import Optional

sys.path.insert(0, str(Path(__file__).parent.parent))

from src.vision_processor import VisionProcessor
from src.character import Character
from src.director import Director
from src.logger import Logger


class NarrationPipeline:
    """
    Visionåˆ†æ â†’ ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å¯¾è©±ç”Ÿæˆ â†’ Directorå“è³ªåˆ¤å®š
    """

    def __init__(self):
        self.vision_processor = VisionProcessor()
        self.char_a = Character("A")
        self.char_b = Character("B")
        self.director = Director()
        self.logger = Logger()

    def _emit_speak_event(
        self,
        run_id: str,
        turn: int,
        speaker: str,
        text: str,
        beat: Optional[str] = None,
    ) -> None:
        """GUIç”¨ã®speakã‚¤ãƒ™ãƒ³ãƒˆã‚’ç™ºè¡Œ"""
        from datetime import datetime
        self.logger.log_event({
            "event": "speak",
            "run_id": run_id,
            "turn": turn,
            "speaker": speaker,
            "text": text,
            "beat": beat,
            "ts": datetime.now().isoformat(),
        })

    def _emit_director_event(
        self,
        run_id: str,
        turn: int,
        beat: str,
        cut_cue: Optional[str] = None,
        status: Optional[str] = None,
        reason: Optional[str] = None,
    ) -> None:
        """GUIç”¨ã®directorã‚¤ãƒ™ãƒ³ãƒˆã‚’ç™ºè¡Œ"""
        from datetime import datetime
        self.logger.log_event({
            "event": "director",
            "run_id": run_id,
            "turn": turn,
            "beat": beat,
            "cut_cue": cut_cue,
            "status": status,
            "reason": reason,
            "ts": datetime.now().isoformat(),
        })

    def _emit_rag_event(
        self,
        run_id: str,
        turn: int,
        char_id: str,
        rag_hints: list,
    ) -> None:
        """GUIç”¨ã®RAGé¸æŠã‚¤ãƒ™ãƒ³ãƒˆã‚’ç™ºè¡Œ"""
        from datetime import datetime

        # RAGãƒ’ãƒ³ãƒˆã‚’ã‚«ãƒ†ã‚´ãƒªåˆ¥ã«æ•´ç†
        canon_preview = ""
        lore_preview = ""
        pattern_preview = ""

        for hint in rag_hints:
            if hint.startswith("["):
                # [domain] content ã®å½¢å¼
                bracket_end = hint.find("]")
                if bracket_end > 0:
                    domain = hint[1:bracket_end].lower()
                    content = hint[bracket_end+1:].strip()[:100]  # æœ€åˆã®100æ–‡å­—

                    if domain in ["sake", "tourism_aesthetics", "cultural_philosophy"]:
                        canon_preview = content
                    elif domain in ["geography", "history", "architecture"]:
                        lore_preview = content
                    else:
                        pattern_preview = content

        self.logger.log_event({
            "event": "rag_select",
            "run_id": run_id,
            "turn": turn,
            "char_id": char_id,
            "canon": {"preview": canon_preview},
            "lore": {"preview": lore_preview},
            "pattern": {"preview": pattern_preview},
            "ts": datetime.now().isoformat(),
        })

    def _build_conversation_context(
        self,
        dialogue_history: list,
        max_turns: int = 3,
    ) -> Optional[str]:
        """
        ç›´è¿‘ã®å¯¾è©±å±¥æ­´ã‹ã‚‰æ–‡è„ˆã‚’æ§‹ç¯‰ã™ã‚‹ã€‚

        Args:
            dialogue_history: [(speaker, text), ...] ã®ãƒªã‚¹ãƒˆ
            max_turns: å«ã‚ã‚‹æœ€å¤§ã‚¿ãƒ¼ãƒ³æ•°

        Returns:
            ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã•ã‚ŒãŸæ–‡è„ˆæ–‡å­—åˆ—ã€ã¾ãŸã¯å±¥æ­´ãŒãªã„å ´åˆã¯None
        """
        if not dialogue_history:
            return None

        # ç›´è¿‘ã®max_turnsåˆ†ã‚’å–å¾—
        recent = dialogue_history[-max_turns:]

        if len(recent) <= 1:
            return None  # ç›´è¿‘1ã‚¿ãƒ¼ãƒ³ã®ã¿ã®å ´åˆã¯æ–‡è„ˆä¸è¦

        lines = []
        for speaker, text in recent[:-1]:  # æœ€å¾Œã®ç™ºè¨€ã¯é™¤ãï¼ˆpartner_speechã§æ¸¡ã•ã‚Œã‚‹ãŸã‚ï¼‰
            char_name = "ã‚„ãª" if speaker == "A" else "ã‚ã‚†"
            lines.append(f"{char_name}: {text}")

        return "\n".join(lines) if lines else None

    def process_image(
        self,
        image_path: Optional[str],
        scene_description: str,
        max_iterations: int = 2,
        run_id: Optional[str] = None,
        skip_vision: bool = False,
    ) -> dict:
        """
        ç”»åƒã¾ãŸã¯ãƒˆãƒ”ãƒƒã‚¯ã«å¯¾ã—ã¦ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ»è§£èª¬ã‚’ç”Ÿæˆã™ã‚‹ã€‚

        Args:
            image_path: å…¥åŠ›ç”»åƒã®ãƒ‘ã‚¹ï¼ˆskip_vision=True ã®å ´åˆã¯ä¸è¦ï¼‰
            scene_description: ã‚·ãƒ¼ãƒ³ã®èª¬æ˜ï¼ˆèª²é¡Œãƒ†ãƒ¼ãƒï¼‰
            max_iterations: ãƒªãƒˆãƒ©ã‚¤ã®æœ€å¤§å›æ•°
            run_id: GUIç”¨ã®ãƒ©ãƒ³ID
            skip_vision: Trueã®å ´åˆã€Visionåˆ†æã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ãƒˆãƒ”ãƒƒã‚¯ã®ã¿ã§å¯¾è©±ç”Ÿæˆ

        Returns:
            {
                "status": "success" | "skip" | "error",
                "scene_description": str,
                "image_path": str,
                "vision_analysis": dict,
                "dialogue": {
                    "char_a_turn_1": str,
                    "char_b_turn_1": str,
                    "char_a_turn_2": str,
                    "char_b_turn_2": str (optional),
                    ...
                },
                "director_verdict": dict,
                "log_id": str (optional)
            }
        """
        # run_id ãŒãªã‘ã‚Œã°ç”Ÿæˆ
        if run_id is None:
            from datetime import datetime
            run_id = f"run_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

        result = {
            "status": "processing",
            "scene_description": scene_description,
            "image_path": image_path,
            "vision_analysis": None,
            "dialogue": {},
            "director_verdict": None,
            "log_id": None,
            "run_id": run_id,
        }

        print(f"\n{'='*60}")
        print(f"ğŸ“· Topic: {scene_description}")
        if not skip_vision and image_path:
            print(f"ğŸ–¼ï¸  Image: {image_path}")
        print(f"ğŸ†” Run ID: {run_id}")
        print(f"{'='*60}")

        # Step 1: Vision åˆ†æï¼ˆskip_vision=True ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—ï¼‰
        vision_text = None
        if skip_vision or not image_path:
            print("\n[Step 1] Skipping Vision analysis (topic-only mode)")
            result["vision_analysis"] = {"status": "skipped", "reason": "topic-only mode"}
        else:
            print("\n[Step 1] Analyzing image with Vision LLM...")
            vision_result = self.vision_processor.analyze_image(image_path)

            if vision_result["status"] == "error":
                print(f"âŒ Vision analysis failed: {vision_result.get('error')}")
                result["status"] = "error"
                result["vision_analysis"] = vision_result
                return result

            print("âœ… Vision analysis complete")
            result["vision_analysis"] = vision_result

            # Vision æƒ…å ±ã‚’ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ç”¨ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«å¤‰æ›
            vision_text = self.vision_processor.format_for_character(
                vision_result["visual_info"]
            )

        # Step 2: ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å¯¾è©±ç”Ÿæˆ
        # max_iterations = å¯¾è©±ã‚¿ãƒ¼ãƒ³æ•°ï¼ˆAâ†’Bâ†’Aâ†’B...ï¼‰
        print("\n[Step 2] Generating character dialogue...")

        dialogue_history = []
        turn_counter = 0

        # A ãŒåˆæ‰‹ã‚’æ‰“ã¤
        print(f"\n  Turn {turn_counter + 1}/{max_iterations}")
        print("    > æ¾„ãƒ¶ç€¬ã‚„ãª (å§‰) is speaking...")
        char_a_speech = self.char_a.speak(
            frame_description=scene_description,
            vision_info=vision_text,
        )
        print(f"      {char_a_speech}")
        result["dialogue"][f"turn_{turn_counter}"] = {"speaker": "A", "text": char_a_speech}
        dialogue_history.append(("A", char_a_speech))
        self._emit_speak_event(run_id, turn_counter, "A", char_a_speech)
        # RAGã‚¤ãƒ™ãƒ³ãƒˆã‚’ç™ºè¡Œ
        self._emit_rag_event(run_id, turn_counter, "A", self.char_a.last_rag_hints)
        turn_counter += 1

        # Director Guidance ã‚’ä¿æŒ
        director_guidance = None

        # æ®‹ã‚Šã®ã‚¿ãƒ¼ãƒ³ã‚’äº¤äº’ã«ç”Ÿæˆ
        for turn in range(1, max_iterations):
            print(f"\n  Turn {turn + 1}/{max_iterations}")

            # å‰ã®ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ã‚’å–å¾—
            last_speaker, last_speech = dialogue_history[-1]

            # æ¬¡ã®ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ã‚’æ±ºå®šï¼ˆäº¤äº’ï¼‰
            if last_speaker == "A":
                current_speaker = "B"
                current_char = self.char_b
                speaker_name = "æ¾„ãƒ¶ç€¬ã‚ã‚† (å¦¹)"
            else:
                current_speaker = "A"
                current_char = self.char_a
                speaker_name = "æ¾„ãƒ¶ç€¬ã‚„ãª (å§‰)"

            # å¯¾è©±å±¥æ­´ã‹ã‚‰ç›´è¿‘ã®æ–‡è„ˆã‚’æ§‹ç¯‰ï¼ˆæœ€å¤§3ã‚¿ãƒ¼ãƒ³åˆ†ï¼‰
            recent_context = self._build_conversation_context(dialogue_history, max_turns=3)

            # ç™ºè¨€ç”Ÿæˆï¼ˆRETRYãƒ«ãƒ¼ãƒ—å¯¾å¿œï¼‰
            max_retries = 2
            retry_count = 0
            speech = None
            director_evaluation = None

            while retry_count < max_retries:
                print(f"    > {speaker_name} is speaking..." + (f" (retry {retry_count})" if retry_count > 0 else ""))

                # Director Guidanceã‚’æ¸¡ã—ã¦ç™ºè¨€ç”Ÿæˆ
                speech = current_char.speak(
                    frame_description=scene_description,
                    partner_speech=last_speech,
                    director_instruction=director_guidance,
                    vision_info=vision_text,
                    conversation_context=recent_context,
                )
                print(f"      {speech}")

                # Director ã«ã‚ˆã‚‹å“è³ªåˆ¤å®š
                print(f"    > Director is judging...")
                previous_speech = dialogue_history[-1][1] if len(dialogue_history) > 0 else None

                director_evaluation = self.director.evaluate_response(
                    frame_description=scene_description,
                    speaker=current_speaker,
                    response=speech,
                    partner_previous_speech=previous_speech,
                    speaker_domains=current_char.domains,
                    conversation_history=dialogue_history,
                )

                print(f"      [{director_evaluation.status.name}] {director_evaluation.reason}")

                # RETRYåˆ¤å®š
                if director_evaluation.status.name == "RETRY":
                    retry_count += 1
                    if retry_count < max_retries:
                        print(f"    ğŸ”„ Retrying with suggestion: {director_evaluation.suggestion}")
                        # æ¬¡ã®å†ç”Ÿæˆæ™‚ã«Directorã®æŒ‡æ‘˜ã‚’åæ˜ 
                        director_guidance = director_evaluation.suggestion
                        continue
                    else:
                        print(f"    âš ï¸ Max retries reached, proceeding with current response")
                break

            # ç™ºè¨€ã‚’è¨˜éŒ²
            result["dialogue"][f"turn_{turn_counter}"] = {"speaker": current_speaker, "text": speech}
            dialogue_history.append((current_speaker, speech))
            self._emit_speak_event(run_id, turn_counter, current_speaker, speech)
            # RAGã‚¤ãƒ™ãƒ³ãƒˆã‚’ç™ºè¡Œ
            self._emit_rag_event(run_id, turn_counter, current_speaker, current_char.last_rag_hints)

            # beat ã‚’æ±ºå®š
            beat_map = {"PASS": "PAYOFF", "RETRY": "BANter", "MODIFY": "PIVOT"}
            beat = beat_map.get(director_evaluation.status.name, "BANter")

            # GUIç”¨ director ã‚¤ãƒ™ãƒ³ãƒˆã‚’ç™ºè¡Œ
            self._emit_director_event(
                run_id,
                turn_counter,
                beat,
                director_evaluation.suggestion,
                status=director_evaluation.status.name,
                reason=director_evaluation.reason,
            )

            # æ¬¡ã®ã‚¿ãƒ¼ãƒ³ã¸ã®Director Guidanceã‚’ç”Ÿæˆï¼ˆPASSã®å ´åˆï¼‰
            if director_evaluation.status.name == "PASS" and turn < max_iterations - 1:
                director_guidance = self.director.get_instruction_for_next_turn(
                    frame_description=scene_description,
                    conversation_so_far=dialogue_history,
                    turn_number=turn_counter + 1,
                )
                if director_guidance:
                    print(f"    ğŸ’¡ Director guidance for next turn: {director_guidance[:50]}...")
            else:
                director_guidance = director_evaluation.suggestion

            # æœ€çµ‚ã‚¿ãƒ¼ãƒ³ã®å ´åˆã®ã¿ verdict ã‚’è¨˜éŒ²
            if turn == max_iterations - 1:
                result["director_verdict"] = {
                    "status": str(director_evaluation.status.name),
                    "reason": director_evaluation.reason,
                    "suggestion": director_evaluation.suggestion,
                }

            turn_counter += 1

            # MODIFY ã®å ´åˆã¯æ—©æœŸçµ‚äº†
            if director_evaluation.status.name == "MODIFY":
                print("\nâš ï¸  Director requested modification. Ending dialogue.")
                result["status"] = "skip"
                break
        else:
            # ãƒ«ãƒ¼ãƒ—ãŒæ­£å¸¸å®Œäº†ã—ãŸå ´åˆ
            print(f"\nâœ… Dialogue completed ({turn_counter} turns)")
            result["status"] = "success"

        # Step 4: ãƒ­ã‚°ã«è¨˜éŒ²
        print("\n[Step 3] Logging to file...")
        log_id = self.logger.log_narration(
            scene_description=scene_description,
            image_path=image_path,
            vision_analysis=result["vision_analysis"],
            dialogue=result["dialogue"],
            director_verdict=result["director_verdict"],
        )
        result["log_id"] = log_id
        print(f"âœ… Logged (ID: {log_id})")

        return result

    def process_batch(
        self,
        image_list: list,
        output_file: Optional[str] = None,
    ) -> list:
        """
        è¤‡æ•°ã®ç”»åƒã‚’å‡¦ç†ã™ã‚‹ã€‚

        Args:
            image_list: [(image_path, scene_description), ...] ã®ãƒªã‚¹ãƒˆ
            output_file: çµæœã‚’JSONã§å‡ºåŠ›ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆoptionalï¼‰

        Returns:
            çµæœã®ãƒªã‚¹ãƒˆ
        """
        results = []

        for image_path, scene_description in image_list:
            result = self.process_image(
                image_path=image_path,
                scene_description=scene_description,
            )
            results.append(result)

        # çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ï¼ˆæŒ‡å®šæ™‚ï¼‰
        if output_file:
            with open(output_file, "w", encoding="utf-8") as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            print(f"\nğŸ“ Results saved to: {output_file}")

        return results


def main():
    """
    ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œä¾‹
    """
    pipeline = NarrationPipeline()

    # ãƒ†ã‚¹ãƒˆç”¨ã®ç”»åƒãƒªã‚¹ãƒˆ
    test_images = [
        ("tests/images/temple_sample.jpg", "å¤ã„å¯ºé™¢ã®å¢ƒå†…ã€‚å‚æ‹å®¢ãŒå°‘ãªãã€é™ã‹ãªæ™‚é–“å¸¯ã®ã‚ˆã†ã§ã™ã€‚"),
        ("tests/images/nature_sample.jpg", "ç·‘è±Šã‹ãªå±±é–“ã®é¢¨æ™¯ã€‚è‡ªç„¶ã«åŒ…ã¾ã‚ŒãŸè¦³å…‰åœ°ã§ã™ã€‚"),
    ]

    if not test_images:
        print("No test images provided.")
        print("Usage: python scripts/run_narration.py")
        print("\nTo test:")
        print("1. ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã«é…ç½®")
        print("2. ä»¥ä¸‹ã‚’ã‚³ãƒ¼ãƒ‰å†…ã§è¨­å®šï¼š")
        print('   test_images = [("path/to/image.jpg", "ã‚·ãƒ¼ãƒ³èª¬æ˜"), ...]')
        print("3. ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œ")
        return

    results = pipeline.process_batch(
        image_list=test_images,
        output_file="runs/narration_results.json",
    )

    print("\n" + "="*60)
    print(f"âœ… Processing complete! ({len([r for r in results if r['status'] == 'success'])} / {len(results)} passed)")
    print("="*60)


if __name__ == "__main__":
    main()
