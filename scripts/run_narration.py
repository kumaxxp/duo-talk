#!/usr/bin/env python3
"""
Vision â†’ Character â†’ Director ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³çµ±åˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
è¦³å…‰åœ°ã®ç”»åƒãƒ»å‹•ç”»ã«å¯¾ã—ã¦ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ»è§£èª¬ã‚’ç”Ÿæˆã—ã€å“è³ªåˆ¤å®šã™ã‚‹ã€‚
"""

import sys
import json
from pathlib import Path
from typing import Optional

sys.path.insert(0, str(Path(__file__).parent.parent))

from src.vision_processor import VisionProcessor
from src.character import Character
from src.director import Director
from src.logger import Logger


class NarrationPipeline:
    """
    Visionåˆ†æ â†’ ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å¯¾è©±ç”Ÿæˆ â†’ Directorå“è³ªåˆ¤å®š
    """

    def __init__(self):
        self.vision_processor = VisionProcessor()
        self.char_a = Character("A")
        self.char_b = Character("B")
        self.director = Director()
        self.logger = Logger()

    def process_image(
        self,
        image_path: str,
        scene_description: str,
        max_iterations: int = 2,
    ) -> dict:
        """
        å˜ä¸€ã®ç”»åƒã«å¯¾ã—ã¦ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ»è§£èª¬ã‚’ç”Ÿæˆã™ã‚‹ã€‚

        Args:
            image_path: å…¥åŠ›ç”»åƒã®ãƒ‘ã‚¹
            scene_description: ã‚·ãƒ¼ãƒ³ã®èª¬æ˜ï¼ˆèª²é¡Œãƒ†ãƒ¼ãƒï¼‰
            max_iterations: ãƒªãƒˆãƒ©ã‚¤ã®æœ€å¤§å›æ•°

        Returns:
            {
                "status": "success" | "skip" | "error",
                "scene_description": str,
                "image_path": str,
                "vision_analysis": dict,
                "dialogue": {
                    "char_a_turn_1": str,
                    "char_b_turn_1": str,
                    "char_a_turn_2": str,
                    "char_b_turn_2": str (optional),
                    ...
                },
                "director_verdict": dict,
                "log_id": str (optional)
            }
        """
        result = {
            "status": "processing",
            "scene_description": scene_description,
            "image_path": image_path,
            "vision_analysis": None,
            "dialogue": {},
            "director_verdict": None,
            "log_id": None
        }

        print(f"\n{'='*60}")
        print(f"ğŸ“· Scene: {scene_description}")
        print(f"ğŸ–¼ï¸  Image: {image_path}")
        print(f"{'='*60}")

        # Step 1: Vision åˆ†æ
        print("\n[Step 1] Analyzing image with Vision LLM...")
        vision_result = self.vision_processor.analyze_image(image_path)

        if vision_result["status"] == "error":
            print(f"âŒ Vision analysis failed: {vision_result.get('error')}")
            result["status"] = "error"
            result["vision_analysis"] = vision_result
            return result

        print("âœ… Vision analysis complete")
        result["vision_analysis"] = vision_result

        # Vision æƒ…å ±ã‚’ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ç”¨ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«å¤‰æ›
        vision_text = self.vision_processor.format_for_character(
            vision_result["visual_info"]
        )

        # Step 2: ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å¯¾è©±ç”Ÿæˆï¼ˆãƒªãƒˆãƒ©ã‚¤ãƒ­ã‚¸ãƒƒã‚¯ä»˜ãï¼‰
        print("\n[Step 2] Generating character dialogue...")

        dialogue_history = []
        for iteration in range(max_iterations):
            print(f"\n  Iteration {iteration + 1}/{max_iterations}")

            # char_a ãŒåˆæ‰‹ã‚’æ‰“ã¤
            if iteration == 0:
                print("    > æ¾„ãƒ¶ç€¬ã‚„ãª (å§‰) is speaking...")
                char_a_speech = self.char_a.speak(
                    frame_description=scene_description,
                    vision_info=vision_text,
                )
                print(f"      {char_a_speech}")
                result["dialogue"][f"char_a_turn_{iteration + 1}"] = char_a_speech
                dialogue_history.append(("A", char_a_speech))

                # char_b ãŒå¿œç­”
                print("    > æ¾„ãƒ¶ç€¬ã‚ã‚† (å¦¹) is speaking...")
                char_b_speech = self.char_b.speak(
                    frame_description=scene_description,
                    partner_speech=char_a_speech,
                    vision_info=vision_text,
                )
                print(f"      {char_b_speech}")
                result["dialogue"][f"char_b_turn_{iteration + 1}"] = char_b_speech
                dialogue_history.append(("B", char_b_speech))

            else:
                # 2ã‚¿ãƒ¼ãƒ³ç›®ä»¥é™ï¼ˆãƒªãƒˆãƒ©ã‚¤æ™‚ï¼‰
                last_speaker = dialogue_history[-1][0]
                if last_speaker == "B":
                    # char_a ãŒå†åº¦ç™ºè¨€
                    print("    > æ¾„ãƒ¶ç€¬ã‚„ãª (å§‰) is responding...")
                    char_a_speech = self.char_a.speak(
                        frame_description=scene_description,
                        partner_speech=dialogue_history[-1][1],
                        vision_info=vision_text,
                    )
                    print(f"      {char_a_speech}")
                    result["dialogue"][f"char_a_turn_{iteration + 1}"] = char_a_speech
                    dialogue_history.append(("A", char_a_speech))
                else:
                    # char_b ãŒå†åº¦ç™ºè¨€
                    print("    > æ¾„ãƒ¶ç€¬ã‚ã‚† (å¦¹) is responding...")
                    char_b_speech = self.char_b.speak(
                        frame_description=scene_description,
                        partner_speech=dialogue_history[-1][1],
                        vision_info=vision_text,
                    )
                    print(f"      {char_b_speech}")
                    result["dialogue"][f"char_b_turn_{iteration + 1}"] = char_b_speech
                    dialogue_history.append(("B", char_b_speech))

            # Step 3: Director ã«ã‚ˆã‚‹å“è³ªåˆ¤å®š
            print(f"    > Director is judging quality...")
            full_dialogue = " ".join([speech for _, speech in dialogue_history])

            director_verdict = self.director.judge(
                dialogue=full_dialogue,
                char_a_domain=self.char_a.domains,
                char_b_domain=self.char_b.domains,
            )

            result["director_verdict"] = director_verdict
            print(f"      Status: {director_verdict['status']}")
            print(f"      Reason: {director_verdict['reason']}")

            # PASS ãªã‚‰çµ‚äº†
            if director_verdict["status"] == "PASS":
                print("\nâœ… Dialogue PASSED director judgment!")
                result["status"] = "success"
                break

            # MODIFY ãªã‚‰çµ‚äº†ï¼ˆä¿®æ­£æŒ‡ç¤ºå¿…è¦ï¼‰
            elif director_verdict["status"] == "MODIFY":
                print("\nâš ï¸  Director requested modification. Skipping.")
                result["status"] = "skip"
                break

            # RETRY ãªã‚‰æ¬¡ã®ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¸
            elif director_verdict["status"] == "RETRY":
                print("  â†» Retrying with director feedback...")
                if iteration < max_iterations - 1:
                    continue
                else:
                    print("  Max iterations reached.")
                    result["status"] = "skip"
                    break

        # Step 4: ãƒ­ã‚°ã«è¨˜éŒ²
        print("\n[Step 3] Logging to file...")
        log_id = self.logger.log_narration(
            scene_description=scene_description,
            image_path=image_path,
            vision_analysis=result["vision_analysis"],
            dialogue=result["dialogue"],
            director_verdict=result["director_verdict"],
        )
        result["log_id"] = log_id
        print(f"âœ… Logged (ID: {log_id})")

        return result

    def process_batch(
        self,
        image_list: list,
        output_file: Optional[str] = None,
    ) -> list:
        """
        è¤‡æ•°ã®ç”»åƒã‚’å‡¦ç†ã™ã‚‹ã€‚

        Args:
            image_list: [(image_path, scene_description), ...] ã®ãƒªã‚¹ãƒˆ
            output_file: çµæœã‚’JSONã§å‡ºåŠ›ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆoptionalï¼‰

        Returns:
            çµæœã®ãƒªã‚¹ãƒˆ
        """
        results = []

        for image_path, scene_description in image_list:
            result = self.process_image(
                image_path=image_path,
                scene_description=scene_description,
            )
            results.append(result)

        # çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ï¼ˆæŒ‡å®šæ™‚ï¼‰
        if output_file:
            with open(output_file, "w", encoding="utf-8") as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            print(f"\nğŸ“ Results saved to: {output_file}")

        return results


def main():
    """
    ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œä¾‹
    """
    pipeline = NarrationPipeline()

    # ãƒ†ã‚¹ãƒˆç”¨ã®ç”»åƒãƒªã‚¹ãƒˆ
    test_images = [
        ("tests/images/temple_sample.jpg", "å¤ã„å¯ºé™¢ã®å¢ƒå†…ã€‚å‚æ‹å®¢ãŒå°‘ãªãã€é™ã‹ãªæ™‚é–“å¸¯ã®ã‚ˆã†ã§ã™ã€‚"),
        ("tests/images/nature_sample.jpg", "ç·‘è±Šã‹ãªå±±é–“ã®é¢¨æ™¯ã€‚è‡ªç„¶ã«åŒ…ã¾ã‚ŒãŸè¦³å…‰åœ°ã§ã™ã€‚"),
    ]

    if not test_images:
        print("No test images provided.")
        print("Usage: python scripts/run_narration.py")
        print("\nTo test:")
        print("1. ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã«é…ç½®")
        print("2. ä»¥ä¸‹ã‚’ã‚³ãƒ¼ãƒ‰å†…ã§è¨­å®šï¼š")
        print('   test_images = [("path/to/image.jpg", "ã‚·ãƒ¼ãƒ³èª¬æ˜"), ...]')
        print("3. ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œ")
        return

    results = pipeline.process_batch(
        image_list=test_images,
        output_file="runs/narration_results.json",
    )

    print("\n" + "="*60)
    print(f"âœ… Processing complete! ({len([r for r in results if r['status'] == 'success'])} / {len(results)} passed)")
    print("="*60)


if __name__ == "__main__":
    main()
