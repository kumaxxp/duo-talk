# duo-talk アーキテクチャ設計

## 概要

duo-talk v2.2 は、JetRacer自動運転車の走行を姉妹AIキャラクター（やな・あゆ）が実況するシステム。

### キャラクター設定

| キャラクター | 役割 | 実行環境 |
|-------------|------|----------|
| やな（姉） | Edge AI、物理デバイス制御担当 | Jetson Orin Nano |
| あゆ（妹） | Cloud AI、分析・計算担当 | サーバー |

---

## 1. 統一パイプライン

### 1.1 実行パス統一

v2.2では3つの実行パスを `UnifiedPipeline` に統一。

```
                    Entry Points
                         │
        ┌────────────────┼────────────────┐
        │                │                │
        ▼                ▼                ▼
   Console          GUI/API           LIVE
   (run_commentary) (api_server)   (run_jetracer_live)
        │                │                │
        └────────────────┼────────────────┘
                         │
                         ▼
               ┌─────────────────┐
               │ UnifiedPipeline │
               │   run_dialogue()│  ← 単発対話
               │   run_batch()   │  ← バッチ実行
               │   run_continuous()│ ← LIVE実行
               └─────────────────┘
                         │
           ┌─────────────┴─────────────┐
           ▼                           ▼
    ┌─────────────┐             ┌─────────────┐
    │  Character  │             │  Director   │
    │  (やな/あゆ) │             │ (会話制御)  │
    └─────────────┘             └─────────────┘
```

### 1.2 主要メソッド

| メソッド | 用途 | 使用場面 |
|----------|------|----------|
| `run_dialogue()` | 単発の対話生成 | Console、GUI単発実行 |
| `run_batch()` | 複数ターンのバッチ実行 | RUNS実行、ファイル入力 |
| `run_continuous()` | 連続フレーム処理 | LIVE実行（JetRacer連携） |

---

## 2. コアコンポーネント

### 2.1 DuoSignals（状態管理）

姉妹間で共有する状態をスレッドセーフに管理。

```python
from src.signals import DuoSignals

signals = DuoSignals()
signals.set_scene_facts({"road_condition": "curve", "speed": 45})
signals.add_event("jetracer", "カーブ進入検知", importance=0.8)
```

### 2.2 Director（会話制御）

対話の流れを制御し、次の発話者と発話意図を決定。

```python
from src.director import Director

director = Director()
decision = director.decide(context, signals)
# → {"next_speaker": "char_a", "intent": "react_to_event"}
```

### 2.3 NoveltyGuard（ループ防止）

同じ話題のループを検知し、切り口変更を促す。

```python
from src.novelty_guard import NoveltyGuard

guard = NoveltyGuard()
check = guard.check(new_response, history)
if check.needs_regeneration:
    # 再生成または切り口変更
```

### 2.4 FewShotInjector（Few-shot注入）

キャラクター性を保つためのFew-shotパターンを注入。

```python
from src.few_shot_injector import FewShotInjector

injector = FewShotInjector()
examples = injector.inject(context, mode="jetracer")
```

---

## 3. 実行モード

### 3.1 一般モード（General）

```bash
python scripts/run_commentary.py --topic "AIについて"
```

- JetRacer関連の用語を使わない
- 一般的な会話・解説向け

### 3.2 JetRacerモード

```bash
python scripts/run_jetracer_live.py
```

- JetRacer走行実況
- センサーデータ連携
- リアルタイム画像解析

---

## 4. ファイル構成

```
src/
├── unified_pipeline.py    # 統一パイプライン
├── character.py           # キャラクター（やな/あゆ）
├── director.py            # 会話制御
├── signals.py             # DuoSignals（状態管理）
├── novelty_guard.py       # ループ防止
├── few_shot_injector.py   # Few-shot注入
├── prompt_loader.py       # プロンプト読み込み
├── prompt_builder.py      # プロンプト構築
├── llm_client.py          # LLMクライアント
├── llm_provider.py        # LLMプロバイダー管理
├── vlm_analyzer.py        # VLM画像解析
└── jetracer_client.py     # JetRacer接続

persona/
├── char_a/                # やな設定
│   ├── prompt.yaml
│   ├── prompt_general.yaml
│   ├── prompt_jetracer.yaml
│   └── deep_values.yaml
├── char_b/                # あゆ設定
│   └── (同上)
├── director/
│   └── prompt.yaml
├── few_shots/
│   └── patterns_general.yaml
├── world_rules.yaml
├── world_rules_general.yaml
└── world_rules_jetracer.yaml

config/
├── llm_backends.yaml      # LLMバックエンド設定
├── llm_provider_state.json # 現在の状態
└── vision_settings.json   # ビジョン設定
```

---

## 5. データフロー

### 5.1 対話生成フロー

```
1. 入力受信（テキスト or JetRacerセンサー or 画像）
         │
2. DuoSignals更新
         │
3. Director決定（次発話者・意図）
         │
4. FewShotInjector（パターン注入）
         │
5. PromptBuilder（プロンプト構築）
         │
6. LLM推論
         │
7. NoveltyGuard（ループチェック）
         │
8. 出力（テキスト + イベント記録）
```

### 5.2 イベント記録

全ての対話は `runs/commentary_runs.jsonl` に記録される。

```json
{"event_type": "speak", "speaker": "char_a", "content": "...", "timestamp": "..."}
```

---

## 6. 設定ファイル

### 6.1 config.yaml

```yaml
llm:
  backend: vllm
  model: gemma3-27b-int4

jetracer:
  host: 192.168.1.100
  port: 8080

commentary:
  turns_per_frame: 4
  frame_interval: 3.0
```

### 6.2 llm_backends.yaml

vLLM / Ollama のバックエンド設定とモデル定義。

---

## 7. 非推奨API

以下のメソッドは非推奨。`UnifiedPipeline` を使用すること。

| 非推奨 | 代替 |
|--------|------|
| `Character.speak()` | `UnifiedPipeline.run_dialogue()` |
| `Character.speak_v2()` | `UnifiedPipeline.run_dialogue()` |
