ã€ã‚¿ã‚¹ã‚¯ã€‘duo-talk v2.1 ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰æ”¹é€  + VLMçµ±åˆ

ã€ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã€‘
C:\work\duo-talk

ã€æ¦‚è¦ã€‘
1. æ—¢å­˜ã®Reactãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ + FastAPIã‚µãƒ¼ãƒãƒ¼ã‚’v2.1å¯¾å¿œã«æ”¹é€ 
2. VLMçµ±åˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ï¼ˆPhase 0ï¼‰ã®å®Ÿè£…

===========================================
Part 1: ã‚µãƒ¼ãƒãƒ¼ã‚µã‚¤ãƒ‰ v2.1 APIè¿½åŠ 
===========================================

ã€ãƒ•ã‚¡ã‚¤ãƒ«ã€‘server/api_v2.py ã‚’æ–°è¦ä½œæˆ
```python
#!/usr/bin/env python3
"""
DUO-TALK v2.1 API Extensions
DuoSignals, NoveltyGuard, SilenceController ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ çŠ¶æ…‹ã‚’é…ä¿¡
"""

import sys
import json
import time
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, Optional, Generator

sys.path.insert(0, str(Path(__file__).parent.parent))

from flask import Blueprint, jsonify, request, Response
from src.signals import DuoSignals, SignalEvent, EventType, DuoSignalsState
from src.novelty_guard import NoveltyGuard, LoopBreakStrategy
from src.silence_controller import SilenceController, SilenceType
from src.character import Character
from src.jetracer_client import JetRacerClient
from src.jetracer_provider import JetRacerProvider, DataMode

# Blueprint for v2.1 APIs
v2_api = Blueprint('v2_api', __name__, url_prefix='/api/v2')

# Global instances
_signals: Optional[DuoSignals] = None
_novelty_guard: Optional[NoveltyGuard] = None
_silence_controller: Optional[SilenceController] = None
_characters: Dict[str, Character] = {}
_jetracer_provider: Optional[JetRacerProvider] = None


def get_signals() -> DuoSignals:
    global _signals
    if _signals is None:
        DuoSignals.reset_instance()
        _signals = DuoSignals()
    return _signals


def get_novelty_guard() -> NoveltyGuard:
    global _novelty_guard
    if _novelty_guard is None:
        _novelty_guard = NoveltyGuard()
    return _novelty_guard


def get_silence_controller() -> SilenceController:
    global _silence_controller
    if _silence_controller is None:
        _silence_controller = SilenceController()
    return _silence_controller


def get_character(char_id: str) -> Character:
    global _characters
    if char_id not in _characters:
        _characters[char_id] = Character(char_id)
    return _characters[char_id]


# ==================== DuoSignals API ====================

@v2_api.route('/signals', methods=['GET'])
def get_signals_state():
    """ç¾åœ¨ã®DuoSignalsçŠ¶æ…‹ã‚’å–å¾—"""
    signals = get_signals()
    state = signals.snapshot()
    
    return jsonify({
        "status": "ok",
        "state": {
            "jetracer_mode": state.jetracer_mode,
            "current_speed": state.current_speed,
            "steering_angle": state.steering_angle,
            "distance_sensors": state.distance_sensors,
            "scene_facts": state.scene_facts,
            "last_speaker": state.last_speaker,
            "turn_count": state.turn_count,
            "current_topic": state.current_topic,
            "topic_depth": state.topic_depth,
            "recent_topics": state.recent_topics[-5:],
            "recent_events": state.recent_events[-3:],
            "last_updated": state.last_updated.isoformat(),
            "is_stale": signals.is_stale()
        }
    })


@v2_api.route('/signals/update', methods=['POST'])
def update_signals():
    """DuoSignalsã‚’æ›´æ–°ï¼ˆãƒ†ã‚¹ãƒˆ/ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ï¼‰"""
    data = request.get_json()
    signals = get_signals()
    
    event_type_str = data.get('event_type', 'sensor')
    event_data = data.get('data', {})
    
    try:
        event_type = EventType(event_type_str)
        signals.update(SignalEvent(event_type=event_type, data=event_data))
        return jsonify({"status": "ok"})
    except Exception as e:
        return jsonify({"status": "error", "message": str(e)}), 400


@v2_api.route('/signals/stream', methods=['GET'])
def stream_signals():
    """DuoSignalsçŠ¶æ…‹ã‚’SSEã§ã‚¹ãƒˆãƒªãƒ¼ãƒ """
    def generate():
        signals = get_signals()
        last_update = None
        
        while True:
            state = signals.snapshot()
            current_update = state.last_updated
            
            # æ›´æ–°ãŒã‚ã£ãŸå ´åˆã®ã¿é€ä¿¡
            if last_update is None or current_update > last_update:
                event_data = {
                    "jetracer_mode": state.jetracer_mode,
                    "current_speed": state.current_speed,
                    "steering_angle": state.steering_angle,
                    "distance_sensors": state.distance_sensors,
                    "scene_facts": state.scene_facts,
                    "turn_count": state.turn_count,
                    "topic_depth": state.topic_depth,
                    "is_stale": signals.is_stale(),
                    "timestamp": current_update.isoformat()
                }
                yield f"event: signals\ndata: {json.dumps(event_data)}\n\n"
                last_update = current_update
            
            time.sleep(0.5)
    
    return Response(generate(), mimetype='text/event-stream',
                   headers={'Cache-Control': 'no-cache'})


# ==================== NoveltyGuard API ====================

@v2_api.route('/novelty/status', methods=['GET'])
def get_novelty_status():
    """NoveltyGuardã®çŠ¶æ…‹ã‚’å–å¾—"""
    guard = get_novelty_guard()
    stats = guard.get_stats()
    
    return jsonify({
        "status": "ok",
        "novelty_guard": stats
    })


@v2_api.route('/novelty/check', methods=['POST'])
def check_novelty():
    """ãƒ†ã‚­ã‚¹ãƒˆã®ãƒ«ãƒ¼ãƒ—æ¤œçŸ¥ã‚’ãƒã‚§ãƒƒã‚¯"""
    data = request.get_json()
    text = data.get('text', '')
    
    guard = get_novelty_guard()
    result = guard.check_and_update(text)
    
    return jsonify({
        "status": "ok",
        "result": {
            "loop_detected": result.loop_detected,
            "stuck_nouns": result.stuck_nouns,
            "strategy": result.strategy.value if result.strategy else None,
            "topic_depth": result.topic_depth,
            "injection": result.injection
        }
    })


# ==================== SilenceController API ====================

@v2_api.route('/silence/check', methods=['GET'])
def check_silence():
    """ç¾åœ¨ã®çŠ¶æ…‹ã§æ²ˆé»™ã™ã¹ãã‹ãƒã‚§ãƒƒã‚¯"""
    signals = get_signals()
    controller = get_silence_controller()
    state = signals.snapshot()
    
    silence = controller.should_silence(state)
    
    if silence:
        return jsonify({
            "status": "ok",
            "should_silence": True,
            "silence": {
                "type": silence.silence_type.value,
                "duration": silence.duration_seconds,
                "allow_short": silence.allow_short_utterance,
                "sfx": silence.suggested_sfx,
                "bgm_intensity": silence.suggested_bgm_intensity
            }
        })
    else:
        return jsonify({
            "status": "ok",
            "should_silence": False
        })


# ==================== Character v2 API ====================

@v2_api.route('/speak', methods=['POST'])
def speak_v2():
    """speak_v2ã‚’ä½¿ã£ãŸç™ºè©±ç”Ÿæˆ"""
    data = request.get_json()
    
    char_id = data.get('character', 'A')
    last_utterance = data.get('last_utterance', '')
    frame_description = data.get('frame_description', '')
    history = data.get('history', [])
    
    character = get_character(char_id)
    
    result = character.speak_v2(
        last_utterance=last_utterance,
        context={"history": history},
        frame_description=frame_description
    )
    
    return jsonify({
        "status": "ok",
        "result": result
    })


# ==================== JetRacer Integration ====================

@v2_api.route('/jetracer/connect', methods=['POST'])
def connect_jetracer():
    """JetRacerã«æ¥ç¶š"""
    global _jetracer_provider
    
    data = request.get_json()
    url = data.get('url', 'http://192.168.1.65:8000')
    mode = data.get('mode', 'sensor_only')
    
    try:
        client = JetRacerClient(url, timeout=5.0)
        status = client.get_status()
        
        if status:
            data_mode = DataMode(mode)
            _jetracer_provider = JetRacerProvider(client, data_mode)
            return jsonify({
                "status": "ok",
                "message": f"Connected to {url}",
                "mode": mode
            })
        else:
            return jsonify({
                "status": "error",
                "message": "Connection failed"
            }), 503
    except Exception as e:
        return jsonify({
            "status": "error",
            "message": str(e)
        }), 500


@v2_api.route('/jetracer/fetch', methods=['GET'])
def fetch_jetracer():
    """JetRacerã‹ã‚‰ãƒ‡ãƒ¼ã‚¿å–å¾—ã—ã¦DuoSignalsã«åæ˜ """
    global _jetracer_provider
    
    if _jetracer_provider is None:
        return jsonify({
            "status": "error",
            "message": "Not connected to JetRacer"
        }), 400
    
    try:
        full_state = _jetracer_provider.fetch()
        
        if not full_state.valid or full_state.sensor is None:
            return jsonify({
                "status": "error",
                "message": "Failed to fetch sensor data"
            }), 503
        
        sensor = full_state.sensor
        signals = get_signals()
        
        # ã‚»ãƒ³ã‚µãƒ¼ã‚¤ãƒ™ãƒ³ãƒˆ
        signals.update(SignalEvent(
            event_type=EventType.SENSOR,
            data={
                "speed": abs(sensor.throttle) * 3.0,
                "steering": sensor.steering * 45,
                "sensors": {
                    "distance": sensor.min_distance,
                    "temperature": sensor.temperature
                }
            }
        ))
        
        # VLMè¦³æ¸¬ï¼ˆVISIONãƒ¢ãƒ¼ãƒ‰æ™‚ï¼‰
        if full_state.vision and full_state.vision.road_percentage > 0:
            signals.update(SignalEvent(
                event_type=EventType.VLM,
                data={
                    "facts": {
                        "road_percentage": f"{full_state.vision.road_percentage:.0f}%",
                        "inference_time": f"{full_state.vision.inference_time_ms:.0f}ms"
                    }
                }
            ))
        
        frame_desc = _jetracer_provider.to_frame_description(full_state)
        
        return jsonify({
            "status": "ok",
            "frame_description": frame_desc,
            "sensor": {
                "speed": sensor.throttle,
                "steering": sensor.steering,
                "distance": sensor.min_distance,
                "temperature": sensor.temperature,
                "mode": sensor.mode
            },
            "vision": {
                "road_percentage": full_state.vision.road_percentage if full_state.vision else 0,
                "inference_time": full_state.vision.inference_time_ms if full_state.vision else 0
            } if full_state.vision else None
        })
    except Exception as e:
        return jsonify({
            "status": "error",
            "message": str(e)
        }), 500


@v2_api.route('/jetracer/stream', methods=['GET'])
def stream_jetracer():
    """JetRacerãƒ‡ãƒ¼ã‚¿ã‚’SSEã§ã‚¹ãƒˆãƒªãƒ¼ãƒ """
    global _jetracer_provider
    
    if _jetracer_provider is None:
        return jsonify({
            "status": "error",
            "message": "Not connected to JetRacer"
        }), 400
    
    interval = float(request.args.get('interval', 1.0))
    
    def generate():
        signals = get_signals()
        
        while True:
            try:
                full_state = _jetracer_provider.fetch()
                
                if full_state.valid and full_state.sensor:
                    sensor = full_state.sensor
                    
                    # DuoSignalsæ›´æ–°
                    signals.update(SignalEvent(
                        event_type=EventType.SENSOR,
                        data={
                            "speed": abs(sensor.throttle) * 3.0,
                            "steering": sensor.steering * 45,
                            "sensors": {
                                "distance": sensor.min_distance,
                                "temperature": sensor.temperature
                            }
                        }
                    ))
                    
                    event_data = {
                        "sensor": {
                            "speed": sensor.throttle,
                            "steering": sensor.steering,
                            "distance": sensor.min_distance,
                            "temperature": sensor.temperature,
                            "mode": sensor.mode
                        },
                        "frame_description": _jetracer_provider.to_frame_description(full_state),
                        "timestamp": datetime.now().isoformat()
                    }
                    
                    if full_state.vision:
                        event_data["vision"] = {
                            "road_percentage": full_state.vision.road_percentage,
                            "inference_time": full_state.vision.inference_time_ms
                        }
                    
                    yield f"event: jetracer\ndata: {json.dumps(event_data)}\n\n"
            except Exception as e:
                yield f"event: error\ndata: {json.dumps({'error': str(e)})}\n\n"
            
            time.sleep(interval)
    
    return Response(generate(), mimetype='text/event-stream',
                   headers={'Cache-Control': 'no-cache'})


# ==================== Live Commentary ====================

@v2_api.route('/live/start', methods=['POST'])
def start_live_commentary():
    """ãƒ©ã‚¤ãƒ–ã‚³ãƒ¡ãƒ³ã‚¿ãƒªãƒ¼ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹"""
    data = request.get_json()
    
    # JetRaceræ¥ç¶šç¢ºèª
    jetracer_url = data.get('jetracer_url', 'http://192.168.1.65:8000')
    turns_per_frame = data.get('turns_per_frame', 4)
    interval = data.get('interval', 3.0)
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³IDç”Ÿæˆ
    session_id = f"live_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    
    return jsonify({
        "status": "ok",
        "session_id": session_id,
        "config": {
            "jetracer_url": jetracer_url,
            "turns_per_frame": turns_per_frame,
            "interval": interval
        }
    })


@v2_api.route('/live/dialogue', methods=['POST'])
def generate_live_dialogue():
    """1ãƒ•ãƒ¬ãƒ¼ãƒ åˆ†ã®å¯¾è©±ã‚’ç”Ÿæˆ"""
    data = request.get_json()
    
    frame_description = data.get('frame_description', '')
    history = data.get('history', [])
    turns = data.get('turns', 2)
    
    signals = get_signals()
    novelty_guard = get_novelty_guard()
    silence_controller = get_silence_controller()
    
    state = signals.snapshot()
    
    # æ²ˆé»™ãƒã‚§ãƒƒã‚¯
    silence = silence_controller.should_silence(state)
    if silence:
        return jsonify({
            "status": "ok",
            "type": "silence",
            "silence": {
                "type": silence.silence_type.value,
                "duration": silence.duration_seconds
            }
        })
    
    # å¯¾è©±ç”Ÿæˆ
    dialogue = []
    for turn in range(turns):
        char_id = "A" if turn % 2 == 0 else "B"
        character = get_character(char_id)
        
        last_utterance = dialogue[-1]["content"] if dialogue else (
            history[-1]["content"] if history else "ï¼ˆç”»é¢ã‚’è¦‹ã¦ã„ã‚‹ï¼‰"
        )
        
        result = character.speak_v2(
            last_utterance=last_utterance,
            context={"history": history + dialogue},
            frame_description=frame_description
        )
        
        if result["type"] == "speech":
            speaker_name = "ã‚„ãª" if char_id == "A" else "ã‚ã‚†"
            dialogue.append({
                "speaker": speaker_name,
                "content": result["content"],
                "debug": result.get("debug", {})
            })
    
    return jsonify({
        "status": "ok",
        "type": "dialogue",
        "dialogue": dialogue
    })
```

ã€ãƒ•ã‚¡ã‚¤ãƒ«ã€‘server/api_server.py ã‚’ç·¨é›†
æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã®æœ€å¾Œï¼ˆif __name__ == '__main__': ã®å‰ï¼‰ã«ä»¥ä¸‹ã‚’è¿½åŠ :
```python
# ==================== v2.1 API Extensions ====================
from server.api_v2 import v2_api
app.register_blueprint(v2_api)
```

===========================================
Part 2: VLMçµ±åˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ (Phase 0)
===========================================

ã€ãƒ•ã‚¡ã‚¤ãƒ«ã€‘src/vlm_analyzer.py ã‚’æ–°è¦ä½œæˆ
```python
#!/usr/bin/env python3
"""
duo-talk v2.1 - VLM Analyzer
ã‚«ãƒ¡ãƒ©ç”»åƒã‚’VLMã§è§£æã—ã€æ§‹é€ åŒ–ã•ã‚ŒãŸè¦³æ¸¬ãƒ‡ãƒ¼ã‚¿ï¼ˆscene_factsï¼‰ã«å¤‰æ›

æ©Ÿèƒ½:
- ç”»åƒã®VLMè§£æï¼ˆè»Šè¼‰ã‚«ãƒ¡ãƒ©è¦–ç‚¹ï¼‰
- æ§‹é€ åŒ–ã•ã‚ŒãŸã‚·ãƒ¼ãƒ³æƒ…å ±ã®æŠ½å‡º
- DuoSignalsã¸ã®è‡ªå‹•æ³¨å…¥
"""

import base64
import json
import httpx
from pathlib import Path
from typing import Dict, Any, Optional
from dataclasses import dataclass, field
from datetime import datetime

from src.config import config
from src.signals import DuoSignals, SignalEvent, EventType


@dataclass
class VLMAnalysisResult:
    """VLMè§£æçµæœ"""
    # åŸºæœ¬æƒ…å ±
    road_condition: str = "unknown"  # clear, wet, rough, obstacle
    visibility: str = "good"  # good, moderate, poor
    lighting: str = "normal"  # bright, normal, dark, backlight
    
    # èµ°è¡Œé–¢é€£
    lane_position: str = "center"  # left, center, right
    upcoming_feature: str = "straight"  # straight, curve_left, curve_right, corner, intersection
    obstacle_detected: bool = False
    obstacle_description: str = ""
    
    # ç’°å¢ƒ
    environment: str = "indoor"  # indoor, outdoor
    surface_type: str = "unknown"  # carpet, tile, asphalt, concrete
    
    # æ•°å€¤ãƒ‡ãƒ¼ã‚¿
    road_percentage: float = 0.0  # èµ°è¡Œå¯èƒ½é ˜åŸŸã®å‰²åˆ
    confidence: float = 0.0
    
    # ç”Ÿãƒ‡ãƒ¼ã‚¿
    raw_description: str = ""
    inference_time_ms: float = 0.0
    timestamp: datetime = field(default_factory=datetime.now)
    
    def to_scene_facts(self) -> Dict[str, str]:
        """DuoSignals.scene_factsç”¨ã®è¾æ›¸ã«å¤‰æ›"""
        facts = {
            "road_condition": self.road_condition,
            "visibility": self.visibility,
            "lighting": self.lighting,
            "lane_position": self.lane_position,
            "upcoming": self.upcoming_feature,
            "environment": self.environment,
            "surface": self.surface_type,
            "road_percentage": f"{self.road_percentage:.0f}%",
        }
        
        if self.obstacle_detected:
            facts["obstacle"] = self.obstacle_description or "detected"
        
        return facts
    
    def to_frame_description(self) -> str:
        """ãƒ•ãƒ¬ãƒ¼ãƒ èª¬æ˜æ–‡ã«å¤‰æ›"""
        parts = []
        
        # èµ°è¡Œé ˜åŸŸ
        if self.road_percentage > 0:
            if self.road_percentage < 30:
                parts.append(f"èµ°è¡Œå¯èƒ½é ˜åŸŸã‚ãšã‹{self.road_percentage:.0f}%")
            elif self.road_percentage < 60:
                parts.append(f"èµ°è¡Œå¯èƒ½é ˜åŸŸ{self.road_percentage:.0f}%")
            else:
                parts.append(f"èµ°è¡Œå¯èƒ½é ˜åŸŸååˆ†ï¼ˆ{self.road_percentage:.0f}%ï¼‰")
        
        # ã‚³ãƒ¼ãƒŠãƒ¼/ç›´ç·š
        feature_map = {
            "straight": "ç›´ç·šåŒºé–“",
            "curve_left": "å·¦ã‚«ãƒ¼ãƒ–",
            "curve_right": "å³ã‚«ãƒ¼ãƒ–",
            "corner": "ã‚³ãƒ¼ãƒŠãƒ¼",
            "intersection": "äº¤å·®ç‚¹",
        }
        if self.upcoming_feature in feature_map:
            parts.append(feature_map[self.upcoming_feature])
        
        # éšœå®³ç‰©
        if self.obstacle_detected:
            desc = self.obstacle_description or "éšœå®³ç‰©"
            parts.append(f"å‰æ–¹ã«{desc}ã‚ã‚Š")
        
        # è·¯é¢çŠ¶æ…‹
        if self.road_condition != "clear":
            condition_map = {
                "wet": "è·¯é¢æ¿¡ã‚Œ",
                "rough": "è·¯é¢è’ã‚Œ",
                "obstacle": "éšœå®³ç‰©ã‚ã‚Š",
            }
            if self.road_condition in condition_map:
                parts.append(condition_map[self.road_condition])
        
        # ç…§æ˜
        if self.lighting != "normal":
            lighting_map = {
                "dark": "æš—ã„",
                "bright": "çœ©ã—ã„",
                "backlight": "é€†å…‰",
            }
            if self.lighting in lighting_map:
                parts.append(lighting_map[self.lighting])
        
        return "ã€‚".join(parts) + "ã€‚" if parts else "é€šå¸¸èµ°è¡Œä¸­ã€‚"


class VLMAnalyzer:
    """
    VLMç”»åƒè§£æå™¨
    
    ä½¿ç”¨ä¾‹:
        analyzer = VLMAnalyzer()
        result = analyzer.analyze_image("path/to/image.jpg")
        
        # DuoSignalsã«æ³¨å…¥
        signals = DuoSignals()
        analyzer.inject_to_signals(result, signals)
    """
    
    # VLMè§£æç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
    ANALYSIS_PROMPT = """ã‚ãªãŸã¯è‡ªå‹•é‹è»¢è»Šã®è»Šè¼‰ã‚«ãƒ¡ãƒ©æ˜ åƒã‚’è§£æã™ã‚‹AIã§ã™ã€‚
ç”»åƒã‚’è¦‹ã¦ã€ä»¥ä¸‹ã®æƒ…å ±ã‚’JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

{
    "road_condition": "clear|wet|rough|obstacle",
    "visibility": "good|moderate|poor",
    "lighting": "bright|normal|dark|backlight",
    "lane_position": "left|center|right",
    "upcoming_feature": "straight|curve_left|curve_right|corner|intersection",
    "obstacle_detected": true|false,
    "obstacle_description": "éšœå®³ç‰©ã®èª¬æ˜ï¼ˆãªã‘ã‚Œã°ç©ºæ–‡å­—ï¼‰",
    "environment": "indoor|outdoor",
    "surface_type": "carpet|tile|asphalt|concrete|unknown",
    "road_percentage": 0-100ï¼ˆèµ°è¡Œå¯èƒ½ãªé ˜åŸŸã®å‰²åˆï¼‰,
    "description": "ã‚·ãƒ¼ãƒ³ã®ç°¡æ½”ãªèª¬æ˜ï¼ˆæ—¥æœ¬èªã§1æ–‡ï¼‰"
}

æ³¨æ„:
- road_percentageã¯ç”»åƒå†…ã§èµ°è¡Œå¯èƒ½ãªé ˜åŸŸã®å‰²åˆã‚’æ¨å®š
- upcoming_featureã¯é€²è¡Œæ–¹å‘ã®é“è·¯å½¢çŠ¶ã‚’åˆ¤æ–­
- ä¸æ˜ãªå ´åˆã¯unknownã‚„0ã‚’ä½¿ç”¨
- JSONã®ã¿ã‚’å‡ºåŠ›ã—ã€ä»–ã®èª¬æ˜ã¯ä¸è¦"""

    def __init__(
        self,
        api_base: str = None,
        model: str = None,
        timeout: float = 30.0
    ):
        """
        Args:
            api_base: VLM APIã®ãƒ™ãƒ¼ã‚¹URLï¼ˆNoneãªã‚‰configä½¿ç”¨ï¼‰
            model: ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«åï¼ˆNoneãªã‚‰configä½¿ç”¨ï¼‰
            timeout: APIã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆç§’æ•°
        """
        self.api_base = api_base or config.openai_base_url
        self.model = model or config.openai_model
        self.timeout = timeout
        self._client = httpx.Client(timeout=timeout)
    
    def analyze_image(self, image_path: str) -> VLMAnalysisResult:
        """
        ç”»åƒã‚’VLMã§è§£æ
        
        Args:
            image_path: ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            
        Returns:
            VLMAnalysisResult: è§£æçµæœ
        """
        start_time = datetime.now()
        result = VLMAnalysisResult()
        
        try:
            # ç”»åƒã‚’base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
            image_path = Path(image_path)
            if not image_path.exists():
                result.raw_description = f"Image not found: {image_path}"
                return result
            
            with open(image_path, 'rb') as f:
                image_data = base64.b64encode(f.read()).decode('utf-8')
            
            # æ‹¡å¼µå­ã‹ã‚‰MIMEã‚¿ã‚¤ãƒ—ã‚’æ¨å®š
            ext = image_path.suffix.lower()
            mime_types = {
                '.jpg': 'image/jpeg',
                '.jpeg': 'image/jpeg',
                '.png': 'image/png',
                '.gif': 'image/gif',
                '.webp': 'image/webp',
            }
            mime_type = mime_types.get(ext, 'image/jpeg')
            
            # VLM APIå‘¼ã³å‡ºã—
            response = self._call_vlm(image_data, mime_type)
            
            # çµæœã‚’ãƒ‘ãƒ¼ã‚¹
            result = self._parse_response(response)
            
        except Exception as e:
            result.raw_description = f"Analysis error: {str(e)}"
        
        # å‡¦ç†æ™‚é–“ã‚’è¨˜éŒ²
        result.inference_time_ms = (datetime.now() - start_time).total_seconds() * 1000
        result.timestamp = datetime.now()
        
        return result
    
    def analyze_base64(self, image_base64: str, mime_type: str = "image/jpeg") -> VLMAnalysisResult:
        """
        base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒã‚’è§£æ
        
        Args:
            image_base64: base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒãƒ‡ãƒ¼ã‚¿
            mime_type: MIMEã‚¿ã‚¤ãƒ—
            
        Returns:
            VLMAnalysisResult: è§£æçµæœ
        """
        start_time = datetime.now()
        result = VLMAnalysisResult()
        
        try:
            response = self._call_vlm(image_base64, mime_type)
            result = self._parse_response(response)
        except Exception as e:
            result.raw_description = f"Analysis error: {str(e)}"
        
        result.inference_time_ms = (datetime.now() - start_time).total_seconds() * 1000
        result.timestamp = datetime.now()
        
        return result
    
    def _call_vlm(self, image_base64: str, mime_type: str) -> str:
        """VLM APIã‚’å‘¼ã³å‡ºã—"""
        # OpenAIäº’æ›APIå½¢å¼
        payload = {
            "model": self.model,
            "messages": [
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": self.ANALYSIS_PROMPT
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:{mime_type};base64,{image_base64}"
                            }
                        }
                    ]
                }
            ],
            "max_tokens": 500,
            "temperature": 0.1
        }
        
        response = self._client.post(
            f"{self.api_base}/chat/completions",
            json=payload,
            headers={"Content-Type": "application/json"}
        )
        response.raise_for_status()
        
        data = response.json()
        return data["choices"][0]["message"]["content"]
    
    def _parse_response(self, response_text: str) -> VLMAnalysisResult:
        """VLMãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒ‘ãƒ¼ã‚¹"""
        result = VLMAnalysisResult()
        result.raw_description = response_text
        
        try:
            # JSONã‚’æŠ½å‡ºï¼ˆ```json...```ã§å›²ã¾ã‚Œã¦ã„ã‚‹å ´åˆã‚‚å¯¾å¿œï¼‰
            json_text = response_text
            if "```json" in json_text:
                json_text = json_text.split("```json")[1].split("```")[0]
            elif "```" in json_text:
                json_text = json_text.split("```")[1].split("```")[0]
            
            data = json.loads(json_text.strip())
            
            result.road_condition = data.get("road_condition", "unknown")
            result.visibility = data.get("visibility", "good")
            result.lighting = data.get("lighting", "normal")
            result.lane_position = data.get("lane_position", "center")
            result.upcoming_feature = data.get("upcoming_feature", "straight")
            result.obstacle_detected = data.get("obstacle_detected", False)
            result.obstacle_description = data.get("obstacle_description", "")
            result.environment = data.get("environment", "indoor")
            result.surface_type = data.get("surface_type", "unknown")
            result.road_percentage = float(data.get("road_percentage", 0))
            result.confidence = 0.8  # ãƒ‘ãƒ¼ã‚¹æˆåŠŸ
            
            if data.get("description"):
                result.raw_description = data["description"]
            
        except (json.JSONDecodeError, KeyError, ValueError) as e:
            result.confidence = 0.3  # ãƒ‘ãƒ¼ã‚¹å¤±æ•—
        
        return result
    
    def inject_to_signals(self, result: VLMAnalysisResult, signals: DuoSignals) -> None:
        """è§£æçµæœã‚’DuoSignalsã«æ³¨å…¥"""
        signals.update(SignalEvent(
            event_type=EventType.VLM,
            data={"facts": result.to_scene_facts()}
        ))
    
    def close(self):
        """ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ã‚¯ãƒ­ãƒ¼ã‚º"""
        self._client.close()
    
    def __enter__(self):
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        self.close()


# ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
_analyzer: Optional[VLMAnalyzer] = None


def get_vlm_analyzer() -> VLMAnalyzer:
    """VLMAnalyzerã‚’å–å¾—ï¼ˆã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ï¼‰"""
    global _analyzer
    if _analyzer is None:
        _analyzer = VLMAnalyzer()
    return _analyzer


def reset_vlm_analyzer() -> None:
    """VLMAnalyzerã‚’ãƒªã‚»ãƒƒãƒˆ"""
    global _analyzer
    if _analyzer:
        _analyzer.close()
    _analyzer = None
```

ã€ãƒ•ã‚¡ã‚¤ãƒ«ã€‘src/vision_to_signals.py ã‚’æ–°è¦ä½œæˆ
```python
#!/usr/bin/env python3
"""
duo-talk v2.1 - Vision to Signals Bridge
VLMå‡ºåŠ›ã‚’æ§‹é€ åŒ–ã—ã¦DuoSignalsã«æµã™ãƒ–ãƒªãƒƒã‚¸

è¨­è¨ˆæ›¸ Phase 0 ã®å®Ÿè£…:
- VLMå‡ºåŠ›ï¼ˆJSON or ãƒ†ã‚­ã‚¹ãƒˆï¼‰ã‚’ãƒ‘ãƒ¼ã‚¹
- æ§‹é€ åŒ–ã—ãŸè¦³æ¸¬ãƒ‡ãƒ¼ã‚¿ã‚’ DuoSignals.scene_facts ã«æ ¼ç´
"""

from typing import Dict, Any, Optional
from dataclasses import dataclass
from datetime import datetime

from src.signals import DuoSignals, SignalEvent, EventType
from src.vlm_analyzer import VLMAnalyzer, VLMAnalysisResult, get_vlm_analyzer


@dataclass
class VisionBridgeConfig:
    """Visionâ†’Signalsãƒ–ãƒªãƒƒã‚¸ã®è¨­å®š"""
    auto_inject: bool = True  # è§£æå¾Œã«è‡ªå‹•ã§Signalsã«æ³¨å…¥
    include_raw: bool = False  # ç”Ÿã®VLMå‡ºåŠ›ã‚‚å«ã‚ã‚‹
    min_confidence: float = 0.5  # æœ€ä½ä¿¡é ¼åº¦ï¼ˆã“ã‚Œä»¥ä¸‹ã¯ç„¡è¦–ï¼‰


class VisionToSignalsBridge:
    """
    Visionè§£æçµæœã‚’DuoSignalsã«å¤‰æ›ãƒ»æ³¨å…¥ã™ã‚‹ãƒ–ãƒªãƒƒã‚¸
    
    ä½¿ç”¨ä¾‹:
        bridge = VisionToSignalsBridge()
        
        # ç”»åƒã‹ã‚‰ç›´æ¥
        result = bridge.process_image("path/to/image.jpg")
        
        # JetRacerã®ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³çµæœã‹ã‚‰
        bridge.process_segmentation_result({
            "road_percentage": 75.0,
            "inference_time_ms": 40.0
        })
    """
    
    def __init__(
        self,
        signals: DuoSignals = None,
        analyzer: VLMAnalyzer = None,
        config: VisionBridgeConfig = None
    ):
        self.signals = signals or DuoSignals()
        self.analyzer = analyzer or get_vlm_analyzer()
        self.config = config or VisionBridgeConfig()
    
    def process_image(self, image_path: str) -> VLMAnalysisResult:
        """
        ç”»åƒã‚’è§£æã—ã¦Signalsã«æ³¨å…¥
        
        Args:
            image_path: ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            
        Returns:
            VLMAnalysisResult: è§£æçµæœ
        """
        result = self.analyzer.analyze_image(image_path)
        
        if self.config.auto_inject and result.confidence >= self.config.min_confidence:
            self._inject_result(result)
        
        return result
    
    def process_image_base64(self, image_base64: str, mime_type: str = "image/jpeg") -> VLMAnalysisResult:
        """
        base64ç”»åƒã‚’è§£æã—ã¦Signalsã«æ³¨å…¥
        """
        result = self.analyzer.analyze_base64(image_base64, mime_type)
        
        if self.config.auto_inject and result.confidence >= self.config.min_confidence:
            self._inject_result(result)
        
        return result
    
    def process_segmentation_result(self, seg_result: Dict[str, Any]) -> None:
        """
        ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³çµæœï¼ˆJetRacer APIã‹ã‚‰ï¼‰ã‚’Signalsã«æ³¨å…¥
        
        Args:
            seg_result: {
                "road_percentage": float,
                "inference_time_ms": float,
                "navigation_hint": str (optional)
            }
        """
        facts = {}
        
        if "road_percentage" in seg_result:
            facts["road_percentage"] = f"{seg_result['road_percentage']:.0f}%"
        
        if "inference_time_ms" in seg_result:
            facts["inference_time"] = f"{seg_result['inference_time_ms']:.0f}ms"
        
        if "navigation_hint" in seg_result:
            hint = seg_result["navigation_hint"]
            if hint in ["left", "right", "straight", "stop"]:
                facts["navigation_hint"] = hint
        
        if facts:
            self.signals.update(SignalEvent(
                event_type=EventType.VLM,
                data={"facts": facts}
            ))
    
    def process_jetracer_vision(self, vision_data: Any) -> None:
        """
        JetRacerProvider.VisionDataã‚’Signalsã«æ³¨å…¥
        
        Args:
            vision_data: JetRacerProvider.fetch()ã§å–å¾—ã—ãŸvisionãƒ‡ãƒ¼ã‚¿
        """
        if vision_data is None:
            return
        
        facts = {}
        
        if hasattr(vision_data, 'road_percentage') and vision_data.road_percentage > 0:
            facts["road_percentage"] = f"{vision_data.road_percentage:.0f}%"
        
        if hasattr(vision_data, 'inference_time_ms') and vision_data.inference_time_ms > 0:
            facts["inference_time"] = f"{vision_data.inference_time_ms:.0f}ms"
        
        if hasattr(vision_data, 'navigation_hint') and vision_data.navigation_hint:
            facts["navigation_hint"] = vision_data.navigation_hint
        
        if facts:
            self.signals.update(SignalEvent(
                event_type=EventType.VLM,
                data={"facts": facts}
            ))
    
    def _inject_result(self, result: VLMAnalysisResult) -> None:
        """è§£æçµæœã‚’Signalsã«æ³¨å…¥"""
        self.analyzer.inject_to_signals(result, self.signals)


# ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
_bridge: Optional[VisionToSignalsBridge] = None


def get_vision_bridge() -> VisionToSignalsBridge:
    """VisionToSignalsBridgeã‚’å–å¾—ï¼ˆã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ï¼‰"""
    global _bridge
    if _bridge is None:
        _bridge = VisionToSignalsBridge()
    return _bridge


def reset_vision_bridge() -> None:
    """VisionToSignalsBridgeã‚’ãƒªã‚»ãƒƒãƒˆ"""
    global _bridge
    _bridge = None
```

===========================================
Part 3: ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ v2.1 ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆè¿½åŠ 
===========================================

ã€ãƒ•ã‚¡ã‚¤ãƒ«ã€‘duo-gui/src/lib/types.ts ã«è¿½åŠ 
```typescript
// v2.1 Types
export type SignalsState = {
  jetracer_mode: string
  current_speed: number
  steering_angle: number
  distance_sensors: Record<string, number>
  scene_facts: Record<string, string>
  turn_count: number
  topic_depth: number
  is_stale: boolean
  timestamp: string
}

export type NoveltyStatus = {
  history_length: number
  recent_strategies: string[]
  current_nouns: string[]
}

export type SilenceInfo = {
  type: string
  duration: number
  allow_short: boolean
  sfx: string | null
  bgm_intensity: number
}

export type LiveDialogue = {
  speaker: string
  content: string
  debug?: {
    loop_detected?: boolean
    strategy?: string
    unfilled_slots?: string[]
    few_shot_used?: boolean
  }
}
```

ã€ãƒ•ã‚¡ã‚¤ãƒ«ã€‘duo-gui/src/components/SignalsPanel.tsx ã‚’æ–°è¦ä½œæˆ
```tsx
import React from 'react'
import type { SignalsState } from '../lib/types'

type Props = {
  signals: SignalsState | null
}

export default function SignalsPanel({ signals }: Props) {
  if (!signals) {
    return (
      <div className="p-4 bg-slate-100 rounded-lg">
        <h3 className="font-medium text-slate-500">Signals: æœªæ¥ç¶š</h3>
      </div>
    )
  }

  const speedColor = signals.current_speed > 2.5 ? 'text-red-600' : 'text-slate-900'
  const staleColor = signals.is_stale ? 'bg-yellow-100' : 'bg-white'

  return (
    <div className={`p-4 rounded-lg shadow ${staleColor}`}>
      <div className="flex items-center justify-between mb-2">
        <h3 className="font-medium">DuoSignals</h3>
        {signals.is_stale && (
          <span className="px-2 py-0.5 text-xs bg-yellow-200 text-yellow-800 rounded">
            STALE
          </span>
        )}
      </div>
      
      <div className="grid grid-cols-2 gap-2 text-sm">
        <div>
          <span className="text-slate-500">Mode:</span>
          <span className="ml-1 font-mono">{signals.jetracer_mode}</span>
        </div>
        <div>
          <span className="text-slate-500">Speed:</span>
          <span className={`ml-1 font-mono ${speedColor}`}>
            {signals.current_speed.toFixed(2)} m/s
          </span>
        </div>
        <div>
          <span className="text-slate-500">Steering:</span>
          <span className="ml-1 font-mono">{signals.steering_angle.toFixed(1)}Â°</span>
        </div>
        <div>
          <span className="text-slate-500">Turn:</span>
          <span className="ml-1 font-mono">#{signals.turn_count}</span>
        </div>
      </div>

      {/* Scene Facts */}
      {Object.keys(signals.scene_facts).length > 0 && (
        <div className="mt-3 pt-2 border-t">
          <h4 className="text-xs text-slate-500 mb-1">Scene Facts</h4>
          <div className="flex flex-wrap gap-1">
            {Object.entries(signals.scene_facts).map(([key, value]) => (
              <span key={key} className="px-2 py-0.5 text-xs bg-blue-100 text-blue-800 rounded">
                {key}: {value}
              </span>
            ))}
          </div>
        </div>
      )}

      {/* Topic Depth */}
      {signals.topic_depth > 0 && (
        <div className="mt-2">
          <span className="text-xs text-slate-500">Topic Depth: </span>
          <span className={`text-xs font-mono ${signals.topic_depth >= 3 ? 'text-orange-600' : ''}`}>
            {signals.topic_depth}
          </span>
          {signals.topic_depth >= 3 && (
            <span className="ml-1 text-xs text-orange-600">âš ï¸ Loop risk</span>
          )}
        </div>
      )}

      {/* Distance Sensors */}
      {Object.keys(signals.distance_sensors).length > 0 && (
        <div className="mt-2">
          <h4 className="text-xs text-slate-500 mb-1">Sensors</h4>
          <div className="flex gap-2 text-xs font-mono">
            {Object.entries(signals.distance_sensors).map(([key, value]) => (
              <span key={key} className="px-1 bg-slate-100 rounded">
                {key}: {typeof value === 'number' ? value.toFixed(0) : value}
              </span>
            ))}
          </div>
        </div>
      )}
    </div>
  )
}
```

ã€ãƒ•ã‚¡ã‚¤ãƒ«ã€‘duo-gui/src/components/LivePanel.tsx ã‚’æ–°è¦ä½œæˆ
```tsx
import React, { useState, useEffect, useRef } from 'react'
import type { SignalsState, LiveDialogue, SilenceInfo } from '../lib/types'

const API = (import.meta as any).env?.VITE_API_BASE || ''

type Props = {
  jetracer_url?: string
}

export default function LivePanel({ jetracer_url = 'http://192.168.1.65:8000' }: Props) {
  const [connected, setConnected] = useState(false)
  const [signals, setSignals] = useState<SignalsState | null>(null)
  const [dialogue, setDialogue] = useState<LiveDialogue[]>([])
  const [silence, setSilence] = useState<SilenceInfo | null>(null)
  const [running, setRunning] = useState(false)
  const [frameDesc, setFrameDesc] = useState('')
  const dialogueEndRef = useRef<HTMLDivElement>(null)

  // Auto-scroll dialogue
  useEffect(() => {
    dialogueEndRef.current?.scrollIntoView({ behavior: 'smooth' })
  }, [dialogue])

  const connect = async () => {
    try {
      const resp = await fetch(`${API}/api/v2/jetracer/connect`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ url: jetracer_url, mode: 'vision' })
      })
      const data = await resp.json()
      if (data.status === 'ok') {
        setConnected(true)
      }
    } catch (e) {
      console.error('Connect error:', e)
    }
  }

  const fetchAndGenerate = async () => {
    if (!connected) return

    try {
      // Fetch JetRacer data
      const fetchResp = await fetch(`${API}/api/v2/jetracer/fetch`)
      const fetchData = await fetchResp.json()
      
      if (fetchData.status !== 'ok') return
      
      setFrameDesc(fetchData.frame_description)

      // Get signals state
      const sigResp = await fetch(`${API}/api/v2/signals`)
      const sigData = await sigResp.json()
      if (sigData.status === 'ok') {
        setSignals(sigData.state)
      }

      // Check silence
      const silResp = await fetch(`${API}/api/v2/silence/check`)
      const silData = await silResp.json()
      
      if (silData.should_silence) {
        setSilence(silData.silence)
        return
      }
      setSilence(null)

      // Generate dialogue
      const dialogueResp = await fetch(`${API}/api/v2/live/dialogue`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          frame_description: fetchData.frame_description,
          history: dialogue.slice(-10),
          turns: 2
        })
      })
      const dialogueData = await dialogueResp.json()
      
      if (dialogueData.type === 'dialogue') {
        setDialogue(prev => [...prev, ...dialogueData.dialogue])
      }
    } catch (e) {
      console.error('Fetch error:', e)
    }
  }

  // Auto-run loop
  useEffect(() => {
    if (!running) return
    
    const interval = setInterval(fetchAndGenerate, 3000)
    return () => clearInterval(interval)
  }, [running, connected, dialogue])

  return (
    <div className="space-y-4">
      {/* Connection */}
      <div className="flex items-center gap-4">
        <input
          type="text"
          defaultValue={jetracer_url}
          className="flex-1 px-3 py-2 border rounded"
          placeholder="JetRacer URL"
        />
        <button
          onClick={connect}
          disabled={connected}
          className={`px-4 py-2 rounded ${connected ? 'bg-green-500 text-white' : 'bg-blue-500 text-white hover:bg-blue-600'}`}
        >
          {connected ? 'âœ“ Connected' : 'Connect'}
        </button>
      </div>

      {/* Controls */}
      {connected && (
        <div className="flex items-center gap-4">
          <button
            onClick={() => setRunning(!running)}
            className={`px-4 py-2 rounded ${running ? 'bg-red-500' : 'bg-green-500'} text-white`}
          >
            {running ? 'â¹ Stop' : 'â–¶ Start'}
          </button>
          <button
            onClick={fetchAndGenerate}
            disabled={running}
            className="px-4 py-2 bg-slate-200 rounded hover:bg-slate-300 disabled:opacity-50"
          >
            ğŸ”„ Single Fetch
          </button>
          <button
            onClick={() => setDialogue([])}
            className="px-4 py-2 bg-slate-200 rounded hover:bg-slate-300"
          >
            ğŸ—‘ Clear
          </button>
        </div>
      )}

      {/* Frame Description */}
      {frameDesc && (
        <div className="p-3 bg-slate-100 rounded text-sm">
          <span className="text-slate-500">ğŸ“ Frame: </span>
          {frameDesc}
        </div>
      )}

      {/* Silence Indicator */}
      {silence && (
        <div className="p-3 bg-purple-100 rounded flex items-center gap-2">
          <span className="text-2xl">ğŸ¤«</span>
          <div>
            <div className="font-medium text-purple-800">Silence: {silence.type}</div>
            <div className="text-sm text-purple-600">Duration: {silence.duration}s</div>
          </div>
        </div>
      )}

      {/* Dialogue */}
      <div className="max-h-96 overflow-y-auto space-y-2 p-4 bg-white rounded-lg shadow">
        {dialogue.map((d, i) => (
          <div key={i} className={`p-2 rounded ${d.speaker === 'ã‚„ãª' ? 'bg-pink-50' : 'bg-blue-50'}`}>
            <div className="flex items-center gap-2">
              <span className="font-medium">{d.speaker === 'ã‚„ãª' ? 'ğŸ‘§' : 'ğŸ‘§'} {d.speaker}</span>
              {d.debug?.loop_detected && (
                <span className="px-1 text-xs bg-orange-200 text-orange-800 rounded">
                  Loop: {d.debug.strategy}
                </span>
              )}
              {d.debug?.few_shot_used && (
                <span className="px-1 text-xs bg-green-200 text-green-800 rounded">
                  Few-shot
                </span>
              )}
            </div>
            <p className="mt-1">{d.content}</p>
          </div>
        ))}
        <div ref={dialogueEndRef} />
      </div>

      {/* Signals State */}
      {signals && (
        <div className="p-3 bg-slate-50 rounded text-xs">
          <div className="flex flex-wrap gap-2">
            <span>Mode: {signals.jetracer_mode}</span>
            <span>Speed: {signals.current_speed.toFixed(2)}</span>
            <span>Turn: #{signals.turn_count}</span>
            <span>TopicDepth: {signals.topic_depth}</span>
            {signals.is_stale && <span className="text-yellow-600">âš ï¸ Stale</span>}
          </div>
        </div>
      )}
    </div>
  )
}
```

===========================================
Part 4: çµ±åˆãƒ†ã‚¹ãƒˆ
===========================================

ã€å®Ÿè¡Œæ‰‹é †ã€‘

1. ã‚µãƒ¼ãƒãƒ¼ã‚µã‚¤ãƒ‰ãƒ†ã‚¹ãƒˆ:
   cd C:\work\duo-talk
   conda activate duo-talk
   python -c "from server.api_v2 import v2_api; print('API v2 loaded OK')"

2. VLM Analyzerãƒ†ã‚¹ãƒˆ:
   python -c "from src.vlm_analyzer import VLMAnalyzer; print('VLM Analyzer loaded OK')"

3. Vision Bridgeãƒ†ã‚¹ãƒˆ:
   python -c "from src.vision_to_signals import get_vision_bridge; print('Vision Bridge loaded OK')"

4. ã‚µãƒ¼ãƒãƒ¼èµ·å‹•:
   python server/api_server.py

5. ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ãƒ“ãƒ«ãƒ‰:
   cd duo-gui
   npm run build

6. ãƒ–ãƒ©ã‚¦ã‚¶ã§ http://localhost:5000 ã«ã‚¢ã‚¯ã‚»ã‚¹

ã€å®Œäº†å ±å‘Šã€‘
1. å„ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ†ã‚¹ãƒˆçµæœ
2. ã‚µãƒ¼ãƒãƒ¼èµ·å‹•ç¢ºèª
3. ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ãƒ“ãƒ«ãƒ‰çµæœ
4. å‹•ä½œç¢ºèªï¼ˆå¯èƒ½ã§ã‚ã‚Œã°ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆï¼‰